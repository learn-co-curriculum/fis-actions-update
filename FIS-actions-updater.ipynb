{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "# import pipreqs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Generate Requirements file](#generate-requirements-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contents(repo_location):\n",
    "    \"\"\"\n",
    "    Checks the contents of the repository.\n",
    "\n",
    "    Args:\n",
    "        repo_location (str): Full repository URL.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the repository contains 'splitter.py'.\n",
    "    \"\"\"\n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = repo_location.split('/')[-1]\n",
    "    api_url = f'https://api.github.com/repos/{owner}/{repo_name}/contents?ref=curriculum'\n",
    "    print(f'Checking contents in {api_url}')\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {'Authorization': f'Bearer {MY_TOKEN}'}\n",
    "    response = requests.get(api_url, headers=headers).json()\n",
    "    list_of_contents = []\n",
    "    for item in response:\n",
    "        list_of_contents.append(item['name'])\n",
    "    return 'splitter.py' in list_of_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_branch(repo_location):\n",
    "    \"\"\"Checks the repository for a curriculum branch which is necessary for the github actions to function\n",
    "\n",
    "    Args:\n",
    "        repo_location (URL): full repository URL\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the repository contains a curriculum branch\n",
    "    \"\"\"\n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = repo_location.split('/')[-1]\n",
    "    api_url = f'https://api.github.com/repos/{owner}/{repo_name}/branches'\n",
    "    print(f'Checking branches in {api_url}')\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {'Authorization': f'Bearer {MY_TOKEN}'}\n",
    "    response = requests.get(api_url, headers=headers).json()\n",
    "    branch_list = []\n",
    "    for branch in response:\n",
    "        branch_list.append(branch['name'])\n",
    "        \n",
    "    return branch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_files_to_repo(repo_location):\n",
    "    \"\"\"\n",
    "    Adds files to the repository.\n",
    "\n",
    "    Args:\n",
    "        repo_location (str): Full repository URL.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the repository URL is invalid.\n",
    "    \"\"\"\n",
    "    branches = check_branch(repo_location)\n",
    "        \n",
    "    if 'curriculum' in branches:\n",
    "        owner = 'learn-co-curriculum'\n",
    "        repo_name = repo_location.split('/')[-1]\n",
    "        api_url = f'https://api.github.com/repos/{owner}/{repo_name}'\n",
    "        print(f'Working on {api_url}')\n",
    "        MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "        headers = {'Authorization': f'Bearer {MY_TOKEN}'}\n",
    "        response = requests.get(api_url, headers=headers).json()\n",
    "        repo_path = os.path.join(os.getcwd(), repo_name)\n",
    "        workflows_path = os.path.join(repo_path, '.github', 'workflows')\n",
    "\n",
    "        if 'ssh_url' in response.keys():\n",
    "            working_dir = os.getcwd()\n",
    "            repo = git.Repo.clone_from(response['ssh_url'], repo_path)\n",
    "            for branch in branches:\n",
    "                if branch == 'curriculum':\n",
    "                    continue\n",
    "                else:\n",
    "                    repo.git.checkout(branch)\n",
    "                    subprocess.run(['git', 'rm', '-r', '--cached', 'dsc-github-actions-files'], cwd=repo_path)\n",
    "                    repo.git.add('.')\n",
    "                    try:\n",
    "                        repo.git.commit(m=\"removed dsc-github-actions-files\")\n",
    "                        subprocess.run(['rm', '-rf', 'dsc-github-actions-files'], cwd=repo_path)\n",
    "                        repo.git.push()\n",
    "                    except git.GitCommandError:\n",
    "                        continue\n",
    "            repo.git.checkout('curriculum')\n",
    "            os.makedirs(workflows_path, exist_ok=True)\n",
    "            yaml_file = 'branch_split.yml'\n",
    "            script_file = 'splitter.py'\n",
    "            yaml_destination = os.path.join(repo_path, '.github', 'workflows', 'branch_split.yml')\n",
    "            script_destination = os.path.join(repo_path, 'splitter.py')\n",
    "            shutil.copyfile(yaml_file, yaml_destination)\n",
    "            shutil.copyfile(script_file, script_destination)\n",
    "            repo.git.add(\".\")\n",
    "            try:\n",
    "                repo.git.commit(m=\"Adding files via FIS actions updater script\")\n",
    "                repo.git.push()\n",
    "                print(f'Added files to {repo_location}.')\n",
    "            except git.GitCommandError:\n",
    "                print('No changes made to repo')\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                repo.git.checkout('main')\n",
    "            except:\n",
    "                repo.git.checkout('master')\n",
    "            os.makedirs(workflows_path, exist_ok=True)\n",
    "            yaml_file = 'branch_split.yml'\n",
    "            yaml_destination = os.path.join(repo_path, '.github', 'workflows', 'branch_split.yml')\n",
    "            shutil.copyfile(yaml_file, yaml_destination)\n",
    "            repo.git.add(\".\")\n",
    "            try:\n",
    "                repo.git.commit(m=\"Adding files via FIS actions updater script\")\n",
    "                repo.git.push()\n",
    "                print(f'Added files to {repo_location}.')\n",
    "            except git.GitCommandError:\n",
    "                print('No changes made to repo')\n",
    "                shutil.rmtree(repo_path)\n",
    "                pass\n",
    "                \n",
    "            shutil.rmtree(repo_path) \n",
    "            print('Cleaning up directory tree')\n",
    "            print('Done updating Actions files')\n",
    "        else:\n",
    "            print(f'{api_url} is not a valid url')            \n",
    "    \n",
    "    else:\n",
    "        print('This repo has no curriculum branch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and add requirements.txt with the following code:\n",
    "repo_location = \"https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab\"\n",
    "\n",
    "owner = 'learn-co-curriculum'\n",
    "repo_name = repo_location.split('/')[-1]\n",
    "api_url = f'https://api.github.com/repos/{owner}/{repo_name}'\n",
    "print(f'Working on {api_url}')\n",
    "MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "headers = {'Authorization': f'Bearer {MY_TOKEN}'}\n",
    "response = requests.get(api_url, headers=headers).json()\n",
    "repo_path = os.path.join(os.getcwd(), repo_name)\n",
    "\n",
    "repo.git.push()\n",
    "repo.git.checkout(repo.remotes.origin.refs['HEAD'].remote_head)\n",
    "os.chdir(repo_path)\n",
    "done = subprocess.run(['pipreqs', repo_path, '--force'], capture_output=True)\n",
    "print(f'Repo path is {repo_path}')\n",
    "print(done.stdout, done.stderr)\n",
    "with open(os.path.join(repo_path, 'requirements.txt'), 'r')as original:\n",
    "    reqs = original.read()\n",
    "with open(os.path.join(working_dir,'master.txt'), 'a')as f:\n",
    "    f.write(reqs)\n",
    "    print('Requirements added to master file')\n",
    "repo.git.add('.')\n",
    "try:\n",
    "    repo.git.commit(m='added requirements.txt')\n",
    "    repo.git.push()\n",
    "except git.GitCommandError:\n",
    "    print('No changes made to the Requirements.txt')\n",
    "    pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all above cells to load all necessary dependencies\n",
    "\n",
    "Replace the URL in the `add_files_to_repo` function with the URL you wish to update with the actions files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Replace the URL below with the URL you wish to add files to\"\n",
    "\n",
    "add_files_to_repo(\"https://github.com/learn-co-curriculum/dsc-prework-jupyter-notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_phases = [(5, 6953)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create a yaml of the entire course content, then extract the github url from each lesson\n",
    "\n",
    "for phase, course in list_of_phases:\n",
    "    os.system(f\"github-to-canvas --query {course} > phase_{phase}_canvas.yml\")\n",
    "    os.system(f\"github-to-canvas --map phase_{phase}_canvas.yml --urls-only > phase_{phase}_canvas.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add actions files to repository\n",
    "df = pd.read_csv(f'phase_5_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    add_files_to_repo(item['url'])\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix images in repo\n",
    "df = pd.read_csv(f'phase_4_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    images_update = subprocess.run(['python', '/Users/jeffreyhinkle/fis-canvas/fis_canvas.py', '-r', '--fix_images', '--remote_url', item['url'], '--s3_directory', 'data-science/images'], capture_output=True)\n",
    "    print(images_update.stdout)\n",
    "\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger Branch Splitter Action from a `csv` of url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger branch splitter action\n",
    "df = pd.read_csv(f'phase_1_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = item.split('/')[-1]\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    branch_headers = {\n",
    "        'Authorization': f'Bearer {MY_TOKEN}'\n",
    "    }\n",
    "    branch_url = f\"\"\"https://api.github.com/repos/{owner}/{repo_name}/branches\"\"\"\n",
    "    branch_response = requests.get(branch_url, branch_headers).json()\n",
    "    \n",
    "    branches = [b['name'] for b  in branch_response]\n",
    "    \n",
    "    if 'master' in branches:\n",
    "        branch = 'master'\n",
    "    else:\n",
    "        branch = 'main'\n",
    "    \n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = item.split('/')[-1]\n",
    "    data = {\n",
    "        \"ref\": branch\n",
    "    }\n",
    "\n",
    "    api_url = f\"\"\"https://api.github.com/repos/{owner}/{repo_name}/actions/workflows/branch_split.yml/dispatches?-d\"\"\"\n",
    "    print(f'triggering workflow in {api_url}')\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {'Authorization': f'Bearer {MY_TOKEN}', \"Accept\": \"application/vnd.github+json\"}\n",
    "    response = requests.post(api_url, headers=headers, json=data)\n",
    "    print(response.status_code)\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'https://github.com/learn-co-curriculum/dsc-introduction-to-numpy'\n",
    "owner = 'learn-co-curriculum'\n",
    "repo_name = repo.split('/')[-1]\n",
    "MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "branch_headers = {\n",
    "    'Authorization': f'Bearer {MY_TOKEN}'\n",
    "}\n",
    "branch_url = f\"\"\"https://api.github.com/repos/{owner}/{repo_name}/branches\"\"\"\n",
    "response = requests.get(branch_url, branch_headers).json()\n",
    "branches = [branch['name'] for branch  in response]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "item = {'url': \"https://github.com/learn-co-curriculum/dsc-seaborn\"}\n",
    "\n",
    "result = subprocess.run(['python', '/Users/jeffreyhinkle/fis-canvas/fis_canvas.py', '-r', '--fix_images', '--remote_url', item['url'], '--s3_directory', 'data-science/images'], capture_output=True)\n",
    "\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Trigger a GitHub Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote trigger a github action\n",
    "repo_location = 'https://github.com/learn-co-curriculum/dsc-introduction-to-numpy'\n",
    "owner = 'learn-co-curriculum'\n",
    "repo_name = repo_location.split('/')[-1]\n",
    "data = {\n",
    "    \"ref\": \"master\"\n",
    "}\n",
    "\n",
    "api_url = f\"\"\"https://api.github.com/repos/{owner}/{repo_name}/actions/workflows/branch_split.yml/dispatches?-d\"\"\"\n",
    "print(f'triggering workflow in {api_url}')\n",
    "MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "headers = {'Authorization': f'Bearer {MY_TOKEN}', \"Accept\": \"application/vnd.github+json\"}\n",
    "response = requests.post(api_url, headers=headers, json=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Requirements file\n",
    "* First you will need to populate 'list_of_phases' with the __phase__ number and canvas __course__ number you are working with.\n",
    "* Ensure you have modified your default canvas credentials in your `bash_profile` to align with the credentials for the instance you are working with.\n",
    "* Run the code to generate the yaml and csv from canvas and ensure the files have been saved in the same folder you are working from currently. (This should happen by default)\n",
    "* Run the cell with the code to generate the requirements files. Take note of any output other than _requirements.txt file updated successfully._ The output will be large so you may need to open it in a text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a phase tuple consists of the phase number and the canvas course number\n",
    "list_of_phases = [(5, 6953)]\n",
    "\n",
    "# this will generate a course yml, and a csv with only the repository urls.\n",
    "for phase, course in list_of_phases:\n",
    "    os.system(f\"github-to-canvas --query {course} > phase_{phase}_canvas.yml\")\n",
    "    os.system(f\"github-to-canvas --map phase_{phase}_canvas.yml --urls-only > phase_{phase}_canvas.csv\")\n",
    "    \n",
    "# before you run the below code, create a file called 'master.txt' in this working directory\n",
    "import pandas as pd\n",
    "import requirements\n",
    "# add requirements file to repository\n",
    "df = pd.read_csv(f'phase_4_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    requirements.generate_requirements_file(item['url'])\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will generate a requirements file for a single repository\n",
    "import requirements\n",
    "repo_location = \"{replace with the html link to the repository}\"\n",
    "\n",
    "requirements.generate_requirements_file(repo_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
