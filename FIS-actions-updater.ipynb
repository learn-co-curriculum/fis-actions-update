{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# run this cell to import the necessary packages first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Generate Requirements file for a course](#generate-requirements-file-for-a-course)  \n",
    "[Generate Requirements file](#generate-a-requirements-file-for-a-single-repository)  \n",
    "[Add actions files to single repo](#add-github-actions-files-to-a-single-repository)  \n",
    "[Add actions files to a course](#add-actions-files-to-a-course)  \n",
    "[Fix Images in a course](#fix-images-in-repositories-of-an-entire-course)  \n",
    "[Trigger Actions for a course](#trigger-branch-splitter-action-from-a-csv-of-urls)  \n",
    "[Trigger Action for a single repository](#remote-trigger-a-github-action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contents(repo_location):\n",
    "    \"\"\"\n",
    "    Checks the contents of the repository.\n",
    "\n",
    "    Args:\n",
    "        repo_location (str): Full repository URL.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the repository contains 'splitter.py'.\n",
    "    \"\"\"\n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = repo_location.split('/')[-1]\n",
    "    api_url = f'https://api.github.com/repos/{owner}/{repo_name}/contents?ref=curriculum'\n",
    "    print(f'Checking contents in {api_url}')\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {'Authorization': f'Bearer {MY_TOKEN}'}\n",
    "    response = requests.get(api_url, headers=headers).json()\n",
    "    list_of_contents = []\n",
    "    for item in response:\n",
    "        list_of_contents.append(item['name'])\n",
    "    return 'splitter.py' in list_of_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_branch(repo_location):\n",
    "    \"\"\"Checks the repository for a curriculum branch which is necessary for the github actions to function\n",
    "\n",
    "    Args:\n",
    "        repo_location (URL): full repository URL\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the repository contains a curriculum branch\n",
    "    \"\"\"\n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = repo_location.split('/')[-1]\n",
    "    api_url = f'https://api.github.com/repos/{owner}/{repo_name}/branches'\n",
    "    print(f'Checking branches in {api_url}')\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {'Authorization': f'Bearer {MY_TOKEN}'}\n",
    "    response = requests.get(api_url, headers=headers).json()\n",
    "    branch_list = []\n",
    "    for branch in response:\n",
    "        branch_list.append(branch['name'])\n",
    "        \n",
    "    return branch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_files_to_repo(repo_location):\n",
    "    \"\"\"\n",
    "    Adds files to the repository.\n",
    "\n",
    "    Args:\n",
    "        repo_location (str): Full repository URL.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the repository URL is invalid.\n",
    "    \"\"\"\n",
    "    branches = check_branch(repo_location)\n",
    "        \n",
    "    if 'curriculum' in branches:\n",
    "        owner = 'learn-co-curriculum'\n",
    "        repo_name = repo_location.split('/')[-1]\n",
    "        api_url = f'https://api.github.com/repos/{owner}/{repo_name}'\n",
    "        print(f'Working on {api_url}')\n",
    "        MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "        headers = {'Authorization': f'Bearer {MY_TOKEN}'}\n",
    "        response = requests.get(api_url, headers=headers).json()\n",
    "        repo_path = os.path.join(os.getcwd(), repo_name)\n",
    "        workflows_path = os.path.join(repo_path, '.github', 'workflows')\n",
    "\n",
    "        if 'ssh_url' in response.keys():\n",
    "            working_dir = os.getcwd()\n",
    "            repo = git.Repo.clone_from(response['ssh_url'], repo_path)\n",
    "            for branch in branches:\n",
    "                if branch == 'curriculum':\n",
    "                    continue\n",
    "                else:\n",
    "                    repo.git.checkout(branch)\n",
    "                    subprocess.run(['git', 'rm', '-r', '--cached', 'dsc-github-actions-files'], cwd=repo_path)\n",
    "                    repo.git.add('.')\n",
    "                    try:\n",
    "                        repo.git.commit(m=\"removed dsc-github-actions-files\")\n",
    "                        subprocess.run(['rm', '-rf', 'dsc-github-actions-files'], cwd=repo_path)\n",
    "                        repo.git.push()\n",
    "                    except git.GitCommandError:\n",
    "                        continue\n",
    "            repo.git.checkout('curriculum')\n",
    "            os.makedirs(workflows_path, exist_ok=True)\n",
    "            yaml_file = 'branch_split.yml'\n",
    "            script_file = 'splitter.py'\n",
    "            yaml_destination = os.path.join(repo_path, '.github', 'workflows', 'branch_split.yml')\n",
    "            script_destination = os.path.join(repo_path, 'splitter.py')\n",
    "            shutil.copyfile(yaml_file, yaml_destination)\n",
    "            shutil.copyfile(script_file, script_destination)\n",
    "            repo.git.add(\".\")\n",
    "            try:\n",
    "                repo.git.commit(m=\"Adding files via FIS actions updater script\")\n",
    "                repo.git.push()\n",
    "                print(f'Added files to {repo_location}.')\n",
    "            except git.GitCommandError:\n",
    "                print('No changes made to repo')\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                repo.git.checkout('main')\n",
    "            except:\n",
    "                repo.git.checkout('master')\n",
    "            os.makedirs(workflows_path, exist_ok=True)\n",
    "            yaml_file = 'branch_split.yml'\n",
    "            yaml_destination = os.path.join(repo_path, '.github', 'workflows', 'branch_split.yml')\n",
    "            shutil.copyfile(yaml_file, yaml_destination)\n",
    "            repo.git.add(\".\")\n",
    "            try:\n",
    "                repo.git.commit(m=\"Adding files via FIS actions updater script\")\n",
    "                repo.git.push()\n",
    "                print(f'Added files to {repo_location}.')\n",
    "            except git.GitCommandError:\n",
    "                print('No changes made to repo')\n",
    "                shutil.rmtree(repo_path)\n",
    "                pass\n",
    "                \n",
    "            shutil.rmtree(repo_path) \n",
    "            print('Cleaning up directory tree')\n",
    "            print('Done updating Actions files')\n",
    "        else:\n",
    "            print(f'{api_url} is not a valid url')            \n",
    "    \n",
    "    else:\n",
    "        print('This repo has no curriculum branch')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all above cells to load all necessary dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add GitHub Actions Files to a _single_ Repository\n",
    "Replace the URL in the `add_files_to_repo` function with the URL you wish to update with the actions files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Replace the URL below with the URL you wish to add files to\"\n",
    "\n",
    "add_files_to_repo(\"https://github.com/learn-co-curriculum/dsc-random-forest-pyspark-intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a yaml from canvas for a course and a csv of all lessons in the course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of phases is a list of tuples with the phase number and the course number. The phase number will be used to name the files when saved\n",
    "list_of_phases = [(5, 6953)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create a yaml of the entire course content, then extract the github url from each lesson and generate a csv of those url's\n",
    "\n",
    "for phase, course in list_of_phases:\n",
    "    os.system(f\"github-to-canvas --query {course} > phase_{phase}_canvas.yml\")\n",
    "    os.system(f\"github-to-canvas --map phase_{phase}_canvas.yml --urls-only > phase_{phase}_canvas.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Actions Files to a Course\n",
    "> You must first generate the csv with the code above in [Create a yaml](#create-a-yaml-from-canvas-for-a-course-and-a-csv-of-all-lessons-in-the-course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add actions files to repository\n",
    "df = pd.read_csv(f'phase_5_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    add_files_to_repo(item['url'])\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Images in Repositories of an Entire Course\n",
    "> You must first generate the csv with the code above in [Create a yaml](#create-a-yaml-from-canvas-for-a-course-and-a-csv-of-all-lessons-in-the-course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix images in repo\n",
    "df = pd.read_csv(f'phase_4_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    images_update = subprocess.run(['python', '/Users/jeffreyhinkle/fis-canvas/fis_canvas.py', '-r', '--fix_images', '--remote_url', item['url'], '--s3_directory', 'data-science/images'], capture_output=True)\n",
    "    print(images_update.stdout)\n",
    "\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger Branch Splitter Action from a `csv` of url's\n",
    "* This will trigger the action for an entire course\n",
    "* If you only wish to trigger a single repo use this: [Trigger single repo action](#remote-trigger-a-github-action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger branch splitter action\n",
    "df = pd.read_csv(f'phase_1_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = item.split('/')[-1]\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    branch_headers = {\n",
    "        'Authorization': f'Bearer {MY_TOKEN}'\n",
    "    }\n",
    "    branch_url = f\"\"\"https://api.github.com/repos/{owner}/{repo_name}/branches\"\"\"\n",
    "    branch_response = requests.get(branch_url, branch_headers).json()\n",
    "    \n",
    "    branches = [b['name'] for b  in branch_response]\n",
    "    \n",
    "    if 'master' in branches:\n",
    "        branch = 'master'\n",
    "    else:\n",
    "        branch = 'main'\n",
    "    \n",
    "    owner = 'learn-co-curriculum'\n",
    "    repo_name = item.split('/')[-1]\n",
    "    data = {\n",
    "        \"ref\": branch\n",
    "    }\n",
    "\n",
    "    api_url = f\"\"\"https://api.github.com/repos/{owner}/{repo_name}/actions/workflows/branch_split.yml/dispatches?-d\"\"\"\n",
    "    print(f'triggering workflow in {api_url}')\n",
    "    MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {'Authorization': f'Bearer {MY_TOKEN}', \"Accept\": \"application/vnd.github+json\"}\n",
    "    response = requests.post(api_url, headers=headers, json=data)\n",
    "    print(response.status_code)\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Trigger a GitHub Action\n",
    "Replace `repo_location` with the url of your repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote trigger a github action\n",
    "repo_location = 'https://github.com/learn-co-curriculum/dsc-random-forest-pyspark-lab'\n",
    "owner = 'learn-co-curriculum'\n",
    "repo_name = repo_location.split('/')[-1]\n",
    "data = {\n",
    "    \"ref\": \"main\"\n",
    "}\n",
    "\n",
    "api_url = f\"\"\"https://api.github.com/repos/{owner}/{repo_name}/actions/workflows/branch_split.yml/dispatches?-d\"\"\"\n",
    "print(f'triggering workflow in {api_url}')\n",
    "MY_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "headers = {'Authorization': f'Bearer {MY_TOKEN}', \"Accept\": \"application/vnd.github+json\"}\n",
    "response = requests.post(api_url, headers=headers, json=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Requirements file for a course\n",
    "Before you begin, create a file called `master.txt` in this repository.\n",
    "* First you will need to populate 'list_of_phases' with the __phase__ number and canvas __course__ number you are working with.\n",
    "* Ensure you have modified your default canvas credentials in your `bash_profile` to align with the credentials for the instance you are working with.\n",
    "* Run the code to [generate the yaml and csv from canvas](#create-a-yaml-from-canvas-for-a-course-and-a-csv-of-all-lessons-in-the-course) and ensure the files have been saved in the same folder you are working from currently. (This should happen by default)\n",
    "* Run the cell with the code to generate the requirements files. Take note of any output other than _requirements.txt file updated successfully._ The output will be large so you may need to open it in a text editor.\n",
    "\n",
    "When you are done with a phase, rename `master.txt` to something like `phase_1_requirements.txt` and create a new blank `master.txt` for the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before you run the below code, create a file called 'master.txt' in this working directory\n",
    "import pandas as pd\n",
    "import requirements\n",
    "# add requirements file to repository\n",
    "df = pd.read_csv(f'phase_4_canvas.csv')\n",
    "df.columns = ['url']\n",
    "completed = []\n",
    "for i, item in df.iterrows():\n",
    "    requirements.generate_requirements_file(item['url'])\n",
    "df = df.drop(df.index[completed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Requirements file for a single repository\n",
    "> See the instructions in [Generate Requirements file for a course](#generate-requirements-file-for-a-course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will generate a requirements file for a single repository\n",
    "import requirements\n",
    "repo_location = \"{replace with the html link to the repository}\"\n",
    "\n",
    "requirements.generate_requirements_file(repo_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
